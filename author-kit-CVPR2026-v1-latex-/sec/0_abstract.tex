\begin{abstract}
The deployment of deep neural networks in safety-critical domains necessitates robust out-of-distribution (OOD) detection. While existing methods demonstrate strong performance on diverse multi-domain benchmarks, they are not specifically tailored to real-world applications where in-distribution data often originates from a single, narrow domain. This paper identifies and theoretically proves the existence of a critical issue that is unique to single-domain settings: \emph{domain feature collapse}. We show, through information theory and bottleneck compression, that models trained on a single domain dataset with a class label objective learn representations that discard domain-specific features, relying predominantly on class features. This collapse results in significantly higher error rates for out-of-domain OOD detection, a failure mode not adequately captured by traditional multi-domain benchmarks. To combat this, we introduce a two-stage domain filtering process as a simple and effective solution. Domain filtering leverages an initial stage to determine if an input is in-domain before subsequently applying a standard OOD detector. Additionally, we propose the Domain Bench, a new benchmark comprised of various single-domain datasets, providing empirical evidence for domain feature collapse as well as a testbed for evaluating solutions. Our experimental results validate our theoretical findings, showing that existing methods struggle with out-of-domain detection in single-domain contexts and that incorporating domain filtering substantially improves performance in these scenarios, underscoring its importance for reliable OOD detection in single-domain applications.
\end{abstract}