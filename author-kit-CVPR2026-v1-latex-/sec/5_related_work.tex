\section{Related Work}
\label{sec:related_work}
 
\paragraph{Out-of-Distribution Detection.} 
Out-of-distribution (OOD) detection refers to identifying inputs that exhibit a semantic shiftâ€”namely, whose labels are not present during training \citep{yang2021generalized}. This capability is essential in high-stakes domains such as autonomous driving, medical imaging, and industrial systems \citep{huang2020survey}. The baseline approach by \citet{hendrycks2016baseline}, which uses softmax confidence, sparked a wave of improved methods. For instance, ODIN introduced input perturbations and temperature scaling to better separate in- and out-distribution samples \citep{liang2017enhancing}, while \citet{lee2018simple} proposed Mahalanobis-distance scoring using intermediate network features. \citet{liu2020energy} later introduced the energy score, offering a theoretically motivated alternative aligned with neural network logit functions. Subsequent innovations include MOS \citep{huang2021mos}, utilizing logit margins, and Deep Adjacent Neighbors \citep{sun2022out}, which leverages feature-space neighborhood consistency using contrastive learning. Recent work by \citet{liu2025detecting} investigates OOD detection through the lens of neural collapse, revealing that collapsed class means in deep networks produce highly discriminative directions that can distinguish OOD inputs. Their method leverages the geometry of learned representations, showing that deviations from the collapsed manifold signal OOD behavior. In a complementary direction, \citet{xu2023scaling} introduce \textsc{SCALE}, a simple and effective post-hoc technique that enhances OOD detection by scaling network activations. They further propose Intermediate Tensor Shaping (ISH) for training-time enhancement, jointly improving ID performance and OOD robustness with minimal computational overhead.


\paragraph{Single Domain Out-of-Distribution Detection.} 
While most theoretical work in OOD detection is in the multi-domain setting, applied research in OOD detection often occurs in single domain settings. Some of these applications are in medical imaging \citep{narayanaswamy2023exploring, zhang2021out, cao2020benchmark}, satellite imagery \citep{le2024detecting, gawlikowski2021out}, agriculture \citep{saadati2024out, li2023mlfanet}, and industrial systems \citep{kim2021wafer, kafunah2023out}.

\paragraph{Information Theory. }
Information theory has long played a foundational role in machine learning, providing theoretical tools for understanding generalization, compression, and representation learning. Shannon's entropy and mutual information are widely used for feature selection, regularization, and learning disentangled representations \cite{shannon1948mathematical,cover2006elements}. The Information Bottleneck (IB) principle introduced by Tishby et al. \cite{tishby2000information} has inspired various deep learning frameworks, such as the variational IB \cite{alemi2016deep}, which approximates the trade-off between compression and prediction. Mutual information estimation techniques have also become critical in unsupervised and self-supervised learning, as in Deep InfoMax \cite{hjelm2018learning} and contrastive learning methods like CPC \cite{oord2018representation}. Moreover, recent work has connected generalization in deep networks to information-theoretic quantities, suggesting that flat minima and compression during training can explain generalization \cite{shwartz2017opening,achille2018emergence}.

